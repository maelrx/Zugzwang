<div align="right">

[ðŸ‡ºðŸ‡¸ Read in English](README.md)

</div>

<div align="center">

# â™Ÿ Zugzwang

**Motor de pesquisa reprodutÃ­vel para empurrar LLMs aos seus limites no xadrez**

[![Python 3.11+](https://img.shields.io/badge/python-3.11%2B-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Status: Pesquisa Ativa](https://img.shields.io/badge/status-pesquisa%20ativa-orange.svg)]()
[![Baseado em: LLM Chess](https://img.shields.io/badge/baseado%20em-LLM%20Chess%20arXiv%3A2512.01992-blueviolet)](https://arxiv.org/abs/2512.01992)

*"Zugzwang" â€” posiÃ§Ã£o de xadrez onde todo lance disponÃ­vel piora sua situaÃ§Ã£o. Usamos isso como cadinho: LLMs conseguem raciocinar para sair dela?*

</div>

---

## O que Ã© o Zugzwang?

Zugzwang Ã© uma **plataforma de pesquisa modular e reprodutÃ­vel** para estudar atÃ© onde LLMs generalistas conseguem chegar no xadrez usando apenas engenharia de prompts, RAG, few-shot learning, chain-of-thought, tool-use e orquestraÃ§Ã£o multi-agente â€” **sem fine-tuning**.

O xadrez nÃ£o Ã© o objetivo em si, mas um **microscÃ³pio**. Sua natureza estruturada e verificÃ¡vel torna o domÃ­nio ideal para medir com rigor o gap entre capacidade bruta e performance aumentada de LLMs â€” lance por lance.

Este projeto estende o benchmark [LLM Chess](https://github.com/maxim-saplin/llm_chess) (Saplin et al., NeurIPS FoRLM 2025, [arXiv:2512.01992](https://arxiv.org/abs/2512.01992)) â€” o framework de referÃªncia para avaliar LLMs via jogo de xadrez â€” explorando sistematicamente as tÃ©cnicas que aquele paper identificou como lacunas: prompting estruturado, calibraÃ§Ã£o via few-shot, geraÃ§Ã£o aumentada por recuperaÃ§Ã£o (RAG) e orquestraÃ§Ã£o mixture-of-agents.

---

## A Pergunta de Pesquisa

> *Usando exclusivamente tÃ©cnicas de manipulaÃ§Ã£o de LLMs â€” system prompts, RAG, few-shot, chain-of-thought, tool-use, orquestraÃ§Ã£o multi-agente â€” e sem fazer fine-tuning em nenhum modelo, atÃ© onde Ã© possÃ­vel empurrar um LLM generalista no xadrez?*

---

## MotivaÃ§Ã£o & Contexto

O paper LLM Chess (Saplin et al., 2025) estabeleceu que:

- A maioria dos LLMs **nÃ£o consegue vencer um jogador aleatÃ³rio** â€” eles falham em seguir instruÃ§Ãµes, nÃ£o em jogar xadrez propriamente
- Apenas modelos com raciocÃ­nio explÃ­cito (o3, o4-mini, Grok 3 Mini) vencem consistentemente contra jogo aleatÃ³rio
- O melhor modelo testado (o3 low) alcanÃ§a apenas **Elo ~758** contra uma engine calibrada â€” pouco acima do jogador mÃ©dio do chess.com
- O **formato FEN supera o tabuleiro Unicode** em atÃ© +21,7 pp para alguns modelos
- Fornecer o **histÃ³rico de lances reduz blunders** drasticamente (de 11,2% para 1,6% no o4-mini)
- **Mixture-of-Agents** combinando modelos de forte raciocÃ­nio + forte seguimento de instruÃ§Ãµes pode dobrar a taxa de vitÃ³rias e atingir 100% de partidas completadas

PorÃ©m, aquele benchmark usou um prompt simples e genÃ©rico, sem exemplos few-shot, sem RAG, sem chain-of-thought estruturado e sem loop de retry com feedback rico. O Zugzwang foi construÃ­do para preencher essas lacunas â€” com rigor e reprodutibilidade.

FundaÃ§Ãµes adicionais:

- **GPT-3.5-turbo-instruct** joga a ~1750 Elo consumindo PGN puro, sugerindo que LLMs possuem conhecimento latente de xadrez suprimido pelo instruction tuning ([Carlini, 2023](https://nicholas.carlini.com/writing/2023/chess-llm.html))
- **3 exemplos triviais de few-shot** melhoram dramaticamente a performance do GPT-4o no xadrez ([Dynomight, 2024](https://dynomight.net/chess/))
- **Transformers treinados em xadrez desenvolvem world models lineares** do estado do tabuleiro ([Karvonen, 2024](https://arxiv.org/abs/2403.15498))
- LLMs falham no xadrez principalmente por **acesso ao conhecimento**, nÃ£o por capacidade de raciocÃ­nio ([arXiv:2507.00726](https://arxiv.org/abs/2507.00726))

---

## Arquitetura

O Zugzwang Ã© construÃ­do em sete camadas progressivas, cada uma testÃ¡vel independentemente:

```
Camada 0 â€” Infraestrutura        Config, gerenciamento de secrets, validaÃ§Ã£o de env
Camada 1 â€” Core Game Engine      BoardManager, game loop, jogadores LLM/Random/Engine
Camada 2 â€” AvaliaÃ§Ã£o             Stockfish, qualidade de lances, estimativa de Elo (MLE)
Camada 3 â€” EstratÃ©gia            Biblioteca de prompts, montagem de contexto, few-shot, validaÃ§Ã£o
Camada 4 â€” Conhecimento / RAG    RecuperaÃ§Ã£o por fase: aberturas, tÃ¡ticas, finais
Camada 5 â€” Multi-Agente          Capability-MoA, agentes especializados, roteador hÃ­brido
Camada 6 â€” Experiment Runner     Batch, resume, guardrails de budget, scheduling
Camada 7 â€” AnÃ¡lise               EstatÃ­sticas, grÃ¡ficos, relatÃ³rios, dashboard React
```

**Invariantes de design fundamentais:**
- Nenhum lance ilegal Ã© aplicado ao tabuleiro â€” jamais
- A avaliaÃ§Ã£o do Stockfish **nunca** Ã© exposta ao LLM durante a partida
- Todo artefato de partida Ã© auto-contido e reprodutÃ­vel a partir de seu seed
- A configuraÃ§Ã£o Ã© imutÃ¡vel apÃ³s o inÃ­cio de um experimento

---

## Estrutura do RepositÃ³rio

```
zugzwang-engine/
â”œâ”€â”€ zugzwang/
â”‚   â”œâ”€â”€ core/           # BoardManager, game loop, jogadores, protocolo
â”‚   â”œâ”€â”€ providers/      # Anthropic, OpenAI, Google, z.ai, mock
â”‚   â”œâ”€â”€ evaluation/     # Stockfish, qualidade de lances, Elo, mÃ©tricas
â”‚   â”œâ”€â”€ strategy/       # Prompts, montador de contexto, few-shot, validador
â”‚   â”œâ”€â”€ knowledge/      # RAG: indexer, retriever, embeddings, vectordb
â”‚   â”‚   â””â”€â”€ sources/    #   ECO aberturas, heurÃ­sticas Lichess, finais
â”‚   â”œâ”€â”€ agents/         # Capability MoA, tÃ¡tico, posicional, final, crÃ­tico
â”‚   â”œâ”€â”€ experiments/    # Runner, scheduler, tracker, resume
â”‚   â”œâ”€â”€ analysis/       # EstatÃ­sticas, grÃ¡ficos, relatÃ³rios
â”‚   â””â”€â”€ api/            # FastAPI layer (substitui o Streamlit)
â”œâ”€â”€ zugzwang-ui/        # Frontend Vite + React + TypeScript
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ defaults.yaml
â”‚   â”œâ”€â”€ baselines/      # benchmark_compat.yaml, best_known_start.yaml
â”‚   â”œâ”€â”€ ablations/      # Configs de condiÃ§Ãµes experimentais
â”‚   â””â”€â”€ models/         # Overrides por modelo
â”œâ”€â”€ data/               # ECO, puzzles, jogos anotados, vectordb (gitignored)
â”œâ”€â”€ results/            # Artefatos de execuÃ§Ã£o e relatÃ³rios (gitignored)
â””â”€â”€ tests/
```

---

## InÃ­cio RÃ¡pido

**PrÃ©-requisitos:** Python 3.11+, uma chave de API de algum provider (ou use o provider `mock` para testes locais), e opcionalmente o [Stockfish](https://stockfishchess.org/download/) para avaliaÃ§Ã£o.

```bash
# Instalar
pip install -e .[dev]

# Validar ambiente
zugzwang env-check --config configs/baselines/best_known_start.yaml

# Dry run (sem chamadas de API, sem partidas)
zugzwang run --config configs/baselines/best_known_start.yaml --dry-run

# Jogar uma partida
zugzwang play --config configs/baselines/best_known_start.yaml

# Rodar um experimento completo (30 partidas, salva artefatos em results/)
zugzwang run --config configs/baselines/best_known_start.yaml

# Avaliar qualidade dos lances com Stockfish
zugzwang evaluate --run-dir results/runs/<run-id>

# Iniciar o servidor de API
zugzwang api
```

### ConfiguraÃ§Ã£o do Ambiente

Copie `.env.example` para `.env` e preencha suas chaves de API:

```bash
cp .env.example .env
# Edite .env e defina ANTHROPIC_API_KEY, OPENAI_API_KEY, etc.
# Para Stockfish: defina STOCKFISH_PATH=/caminho/para/stockfish
```

---

## ReferÃªncia de Comandos

| Comando | DescriÃ§Ã£o |
|---|---|
| `zugzwang run --config <path>` | Rodar um experimento completo |
| `zugzwang run --config <path> --dry-run` | Validar config sem executar |
| `zugzwang run --config <path> --resume` | Retomar execuÃ§Ã£o mais recente compatÃ­vel |
| `zugzwang run --config <path> --resume-run-id <id>` | Retomar execuÃ§Ã£o especÃ­fica |
| `zugzwang play --config <path>` | Jogar uma Ãºnica partida |
| `zugzwang env-check --config <path>` | Validar credenciais de providers |
| `zugzwang evaluate --run-dir <path>` | AvaliaÃ§Ã£o Stockfish pÃ³s-execuÃ§Ã£o |
| `zugzwang api` | Iniciar servidor de API (porta 8000) |

### Overrides via CLI

Qualquer chave de configuraÃ§Ã£o pode ser sobrescrita inline com `--set`:

```bash
zugzwang play --config configs/baselines/best_known_start.yaml \
  --set players.black.model=claude-opus-4-5 \
  --set strategy.board_format=fen \
  --set strategy.few_shot.enabled=true \
  --set strategy.few_shot.num_examples=3
```

---

## Funcionalidades Principais

### Dois Baselines

| Baseline | Config | Finalidade |
|---|---|---|
| `benchmark_compat` | `configs/baselines/benchmark_compat.yaml` | ReproduÃ§Ã£o fiel do protocolo LLM Chess |
| `best_known_start` | `configs/baselines/best_known_start.yaml` | Modo direto + FEN + lances legais + histÃ³rico (melhor config empiricamente conhecida) |

### Pipeline de EstratÃ©gia

O bloco `strategy` controla tudo que o LLM recebe:

```yaml
strategy:
  board_format: fen          # fen | ascii | combined | unicode (padrÃ£o: fen)
  provide_legal_moves: true
  provide_history: last_n
  history_length: 10
  few_shot:
    enabled: true
    num_examples: 3
    phase_specific: true     # Exemplos diferentes por abertura/middlegame/final
  validation:
    enabled: true
    max_retries: 3
    feedback_level: rich     # minimal | moderate | rich
```

### RAG â€” RecuperaÃ§Ã£o Aumentada (Fase 4 â€” DisponÃ­vel)

RecuperaÃ§Ã£o de conhecimento determinÃ­stica por fase, a partir de fontes locais:

```bash
zugzwang play --config configs/baselines/best_known_start.yaml \
  --set strategy.rag.enabled=true \
  --set strategy.rag.max_chunks=3 \
  --set strategy.rag.include_sources.eco=true \
  --set strategy.rag.include_sources.lichess=true \
  --set strategy.rag.include_sources.endgames=true
```

Fontes: princÃ­pios de aberturas ECO, heurÃ­sticas tÃ¡ticas/posicionais Lichess, teoria de finais.

Config de ablaÃ§Ã£o RAG: `configs/ablations/rag_variants.yaml`

### Multi-Agente â€” MoA (Fase 5 â€” DisponÃ­vel)

OrquestraÃ§Ã£o Mixture-of-Agents com trÃªs modos configurÃ¡veis:
- `capability_moa`: proposers por perfil de capacidade (raciocÃ­nio/compliance/seguranÃ§a)
- `specialist_moa`: proposers especializados (tÃ¡tico/posicional/final)
- `hybrid_phase_router`: roteamento de proposers por fase do jogo

```bash
zugzwang play --config configs/baselines/best_known_start.yaml \
  --set strategy.multi_agent.enabled=true \
  --set strategy.multi_agent.mode=capability_moa \
  --set strategy.multi_agent.proposer_count=2
```

Configs de ablaÃ§Ã£o disponÃ­veis:
- `configs/ablations/moa_capability.yaml`
- `configs/ablations/moa_specialist.yaml`
- `configs/ablations/moa_hybrid_phase.yaml`

### Guardrails de Budget e Confiabilidade

```yaml
budget:
  max_total_usd: 5.00                         # Parada forÃ§ada
  estimated_avg_cost_per_game_usd: 0.55       # Para parada projetada

runtime:
  timeout_policy:
    enabled: true
    min_games_before_enforcement: 5
    max_provider_timeout_game_rate: 0.30      # Para se >30% das partidas darem timeout
    min_observed_completion_rate: 0.60
    action: stop_run
```

### Engine Player (UCI)

Jogue contra o Stockfish com nÃ­vel de habilidade configurÃ¡vel:

```bash
zugzwang play --config configs/baselines/best_known_start.yaml \
  --set players.white.type=engine \
  --set players.white.depth=8
```

### IntegraÃ§Ã£o z.ai / GLM-5

```bash
zugzwang env-check --config configs/baselines/best_known_start_zai_glm5.yaml
zugzwang play --config configs/baselines/best_known_start_zai_glm5.yaml
```

### Frontend â€” FastAPI + React (Fase 7 â€” Em desenvolvimento)

A arquitetura atual usa um servidor **FastAPI** sobre os services Python existentes e um frontend **Vite + React + TypeScript** em `zugzwang-ui/`.

Iniciar o servidor de API:

```bash
pip install -e .[api]
zugzwang api                         # serve na localhost:8000
zugzwang api --reload                # modo dev com hot-reload
```

Em desenvolvimento, rodar o frontend separadamente:

```bash
cd zugzwang-ui && npm install && npm run dev   # Vite na localhost:5173
```

Em produÃ§Ã£o, `zugzwang api` serve o frontend compilado como arquivos estÃ¡ticos â€” um processo, uma porta.

**PÃ¡ginas do frontend:**

| PÃ¡gina | Rota | DescriÃ§Ã£o |
|---|---|---|
| Dashboard | `/` | Jobs ativos, runs recentes, gasto total |
| Run Lab | `/run-lab` | Configurar, validar e lanÃ§ar experimentos |
| Job Monitor | `/jobs/:id` | Log em tempo real (SSE), barra de progresso, cancelar |
| Run Explorer | `/runs` | Navegar todos os runs, filtrar, ordenar |
| Run Detail | `/runs/:id` | Abas de mÃ©tricas, qualidade de lances, config, evaluate |
| Game Replay | `/runs/:id/games/:n` | Replay do tabuleiro, mÃ©tricas por lance, trace MoA |
| ComparaÃ§Ã£o | `/runs/compare` | ComparaÃ§Ã£o lado-a-lado com grÃ¡ficos sobrepostos |
| Settings | `/settings` | Status de env check por provider |

**Stack:** FastAPI Â· Uvicorn Â· Vite Â· React 19 Â· TypeScript Â· TanStack Router Â· TanStack Query Â· Zustand Â· shadcn/ui Â· Tailwind Â· react-chessboard

Tipos TypeScript gerados automaticamente do schema OpenAPI do FastAPI â€” nunca escritos Ã  mÃ£o:

```bash
npx openapi-typescript http://localhost:8000/openapi.json -o src/api/schema.ts
```

EspecificaÃ§Ã£o completa de arquitetura: [`techdocs/FRONTEND_ARCHITECTURE.md`](../techdocs/FRONTEND_ARCHITECTURE.md)

---

## Artefatos de ExecuÃ§Ã£o

Cada execuÃ§Ã£o cria um diretÃ³rio em `results/runs/<run-id>/`:

```
results/runs/<run-id>/
â”œâ”€â”€ resolved_config.yaml              # Config completa mesclada
â”œâ”€â”€ config_hash.txt                   # Fingerprint determinÃ­stico da config
â”œâ”€â”€ _run.json                         # Metadados de execuÃ§Ã£o (secrets redactados)
â”œâ”€â”€ games/
â”‚   â”œâ”€â”€ game_0001.json                # Artefato por partida com trace completo
â”‚   â”œâ”€â”€ game_0002.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ experiment_report.json            # MÃ©tricas agregadas
â””â”€â”€ experiment_report_evaluated.json  # Qualidade de lances + Elo (apÃ³s evaluate)
```

Cada `GameRecord` inclui: sequÃªncia de lances, metadados de retry, uso de tokens, latÃªncia por lance, custo, motivo de encerramento e traces de RAG/MoA quando habilitados.

---

## Protocolo Experimental

O design experimental Ã© estruturado para maximizar o sinal cientÃ­fico por real gasto â€” evitando refazer ablaÃ§Ãµes que o paper base jÃ¡ cobriu.

| Fase | Objetivo | CondiÃ§Ãµes |
|---|---|---|
| **1 â€” CalibraÃ§Ã£o de Baseline** | Confirmar que nosso sistema replica os resultados do LLM Chess (Â±5%) | ~50 partidas |
| **2 â€” AblaÃ§Ã£o de Prompting** | Isolar impacto de: few-shot, CoT posicional, feedback rico no retry, formato de entrada | 30 partidas por condiÃ§Ã£o |
| **3 â€” RAG Progressivo** | Medir ganho marginal de cada fonte de conhecimento (aberturas, tÃ¡ticas, finais) | 30 partidas por condiÃ§Ã£o |
| **4 â€” Full Pipeline** | Melhor config contra Stockfish em mÃºltiplos nÃ­veis â€” estimar Elo com IC de 95% | 50+ partidas por nÃ­vel |
| **5 â€” AnÃ¡lise Cross-Model** | Rodar a config vencedora em todos os modelos testados | 30 partidas por modelo |

### MÃ©tricas

**PrimÃ¡rias:** Win Rate, Elo estimado (MLE), Game Completion Rate

**Qualidade dos Lances:** ACPL (Average Centipawn Loss), taxa de blunders, acordo com top-1 do Stockfish, distribuiÃ§Ã£o de categorias (brilliant/excellent/good/inaccuracy/mistake/blunder)

**Por Fase do Jogo:** ACPL separado para abertura, middlegame e endgame; degradaÃ§Ã£o temporal (ACPL como funÃ§Ã£o do nÃºmero do lance)

**Custo e Robustez:** Tokens por lance, custo por partida, taxa de lances ilegais, taxa de conclusÃ£o de protocolo

---

## Roadmap de Desenvolvimento

| Fase | Status | O que habilita |
|---|---|---|
| Fase 0 â€” Bootstrap | âœ… Completo | Config reprodutÃ­vel, CLI, validaÃ§Ã£o de env |
| Fase 1 â€” Core Engine | âœ… Completo | Partidas legais, todos os tipos de jogador, modos de protocolo |
| Fase 2 â€” AvaliaÃ§Ã£o | âœ… Funcional | Scoring Stockfish, ACPL, Elo MLE, taxa de blunders |
| Fase 3 â€” EstratÃ©gia | âœ… Funcional | Prompts, montagem de contexto, few-shot, validaÃ§Ã£o |
| Fase 4 â€” RAG | âœ… MVP | RecuperaÃ§Ã£o local por fase, configs de ablaÃ§Ã£o |
| Fase 5 â€” Multi-Agente | ðŸ”„ Baseline+ | Modos capability, specialist e hybrid phase-router MoA |
| Fase 6 â€” Experiment Runner | ðŸ”„ Parcial | Batch + resume + budget; queue scheduler pendente |
| Fase 7 â€” AnÃ¡lise | ðŸ”„ Parcial | FastAPI + React dashboard em desenvolvimento |

**PrÃ³ximos alvos:** MoA especialista/hÃ­brido, scheduler com fila, visualizaÃ§Ãµes comparativas e export de anÃ¡lise.

---

## Desenvolvimento

```bash
# Instalar com dependÃªncias de dev
pip install -e .[dev]

# Rodar todos os testes
pytest -q

# Instalar com dependÃªncias de API
pip install -e .[api]
zugzwang api --host 127.0.0.1 --port 8000
```

Os testes cobrem: legalidade do tabuleiro, hash de configuraÃ§Ã£o, parsing de lances, polÃ­ticas de retry, matemÃ¡tica do Elo, recuperaÃ§Ã£o RAG, orquestraÃ§Ã£o MoA, resume/dedup do runner, enforcement de budget.

---

## ReferÃªncias

### ReferÃªncias PrimÃ¡rias

1. **Kolasani, S., Saplin, M. et al.** (2025). *LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess.* NeurIPS FoRLM 2025. [arXiv:2512.01992](https://arxiv.org/abs/2512.01992) Â· [CÃ³digo](https://github.com/maxim-saplin/llm_chess)

2. **Karvonen, A.** (2024). *Emergent World Models and Latent Variable Estimation in Chess-Playing Language Models.* COLM 2024. [arXiv:2403.15498](https://arxiv.org/abs/2403.15498)

3. **Feng, X. et al.** (2023). *ChessGPT: Bridging Policy Learning and Language Modeling.* NeurIPS 2023. [arXiv:2306.09200](https://arxiv.org/abs/2306.09200)

4. **Zhang, Y. et al.** (2025). *Complete Chess Games Enable LLM Become A Chess Master.* NAACL 2025. [arXiv:2501.17186](https://arxiv.org/abs/2501.17186)

5. **Monroe, D. & Leela Chess Zero Team** (2024). *Mastering Chess with a Transformer Model.* [arXiv:2409.12272](https://arxiv.org/abs/2409.12272)

6. **Ruoss, A. et al.** (2024). *Amortized Planning with Large-Scale Transformers: A Case Study on Chess.* NeurIPS 2024. [arXiv:2402.04494](https://arxiv.org/abs/2402.04494)

7. **Anonymous** (2025). *Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess.* [arXiv:2507.00726](https://arxiv.org/abs/2507.00726)

### Blog Posts e AnÃ¡lises

8. **Carlini, N.** (2023). *Playing chess with large language models.* [nicholas.carlini.com](https://nicholas.carlini.com/writing/2023/chess-llm.html)

9. **Dynomight** (2024). *Something weird is happening with LLMs and chess.* [dynomight.net](https://dynomight.net/chess/)

10. **Dynomight** (2024). *OK, I can partly explain the LLM chess weirdness now.* [dynomight.net](https://dynomight.net/chess2/)

11. **Karvonen, A.** (2024). *Chess-GPT's Internal World Model.* [adamkarvonen.github.io](https://adamkarvonen.github.io/machine_learning/2024/01/03/chess-world-models.html)

---

## LicenÃ§a

MIT. Veja [LICENSE](LICENSE).

---

<div align="center">
<sub>ConstruÃ­do com rigor, curiosidade e profundo respeito pelo jogo.</sub>
</div>
